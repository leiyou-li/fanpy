#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Spider Sites Sync Script
å°† spider.json ä¸­çš„ sites é…ç½®åŒæ­¥åˆ° moyun.json ä¸­
"""

import json
import os
import sys
from datetime import datetime
from pathlib import Path


def load_json_file(file_path):
    """å®‰å…¨åŠ è½½JSONæ–‡ä»¶"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return None
    except json.JSONDecodeError as e:
        print(f"âŒ JSONæ ¼å¼é”™è¯¯ {file_path}: {e}")
        return None
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return None


def save_json_file(data, file_path, backup=True):
    """å®‰å…¨ä¿å­˜JSONæ–‡ä»¶"""
    try:
        # åˆ›å»ºå¤‡ä»½
        if backup and os.path.exists(file_path):
            backup_path = f"{file_path}.backup.{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            os.rename(file_path, backup_path)
            print(f"ğŸ“ å·²åˆ›å»ºå¤‡ä»½: {backup_path}")
        
        # ä¿å­˜æ–‡ä»¶
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… æ–‡ä»¶ä¿å­˜æˆåŠŸ: {file_path}")
        return True
    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return False


def validate_site_item(site):
    """éªŒè¯siteé¡¹ç›®çš„å¿…è¦å­—æ®µ"""
    required_fields = ['key', 'name', 'type', 'api']
    for field in required_fields:
        if field not in site:
            return False, f"ç¼ºå°‘å¿…è¦å­—æ®µ: {field}"
    return True, None


def transform_api_path(site):
    """è½¬æ¢APIè·¯å¾„ï¼Œå°†./app/å’Œ./web/è½¬æ¢ä¸º./plugin/app/å’Œ./plugin/web/"""
    if 'api' in site:
        api_path = site['api']
        if api_path.startswith('./app/'):
            site['api'] = api_path.replace('./app/', './plugin/app/')
        elif api_path.startswith('./web/'):
            site['api'] = api_path.replace('./web/', './plugin/web/')
    return site


def sync_sites(spider_file, moyun_file, dry_run=False):
    """
    åŒæ­¥sitesé…ç½®
    
    Args:
        spider_file: spider.json æ–‡ä»¶è·¯å¾„
        moyun_file: moyun.json æ–‡ä»¶è·¯å¾„  
        dry_run: æ˜¯å¦åªè¿›è¡Œé¢„è§ˆä¸å®é™…ä¿®æ”¹æ–‡ä»¶
    """
    print("ğŸš€ å¼€å§‹åŒæ­¥sitesé…ç½®...")
    print(f"ğŸ“– æºæ–‡ä»¶: {spider_file}")
    print(f"ğŸ“ ç›®æ ‡æ–‡ä»¶: {moyun_file}")
    
    # åŠ è½½æºæ–‡ä»¶
    spider_data = load_json_file(spider_file)
    if spider_data is None:
        return False
    
    # åŠ è½½ç›®æ ‡æ–‡ä»¶
    moyun_data = load_json_file(moyun_file)
    if moyun_data is None:
        return False
    
    # æå–å¹¶éªŒè¯sitesæ•°æ®
    spider_sites = spider_data.get('sites', [])
    if not spider_sites:
        print("âš ï¸  spider.json ä¸­æ²¡æœ‰æ‰¾åˆ°sitesé…ç½®")
        return True
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(spider_sites)} ä¸ªsitesé…ç½®é¡¹")
    
    # éªŒè¯sitesæ•°æ®
    valid_sites = []
    invalid_count = 0
    
    for i, site in enumerate(spider_sites):
        is_valid, error_msg = validate_site_item(site)
        if is_valid:
            # è½¬æ¢APIè·¯å¾„
            transformed_site = transform_api_path(site.copy())
            valid_sites.append(transformed_site)
        else:
            print(f"âš ï¸  è·³è¿‡æ— æ•ˆé…ç½®é¡¹ [{i+1}]: {error_msg} - {site.get('name', 'Unknown')}")
            invalid_count += 1
    
    print(f"âœ… æœ‰æ•ˆé…ç½®é¡¹: {len(valid_sites)}")
    if invalid_count > 0:
        print(f"âš ï¸  æ— æ•ˆé…ç½®é¡¹: {invalid_count}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å˜åŒ–
    current_sites = moyun_data.get('sites', [])
    if current_sites == valid_sites:
        print("â„¹ï¸  é…ç½®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€åŒæ­¥")
        return True
    
    # æ˜¾ç¤ºå˜æ›´ä¿¡æ¯
    print(f"ğŸ“ˆ å½“å‰moyun.jsonä¸­æœ‰ {len(current_sites)} ä¸ªsites")
    print(f"ğŸ”„ å°†æ›´æ–°ä¸º {len(valid_sites)} ä¸ªsites")
    
    if dry_run:
        print("ğŸ” é¢„è§ˆæ¨¡å¼ - ä¸ä¼šå®é™…ä¿®æ”¹æ–‡ä»¶")
        print("ğŸ“‹ å°†è¦åŒæ­¥çš„sitesé…ç½®:")
        for i, site in enumerate(valid_sites[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"  {i+1}. {site['name']} ({site['key']})")
        if len(valid_sites) > 5:
            print(f"  ... è¿˜æœ‰ {len(valid_sites) - 5} ä¸ª")
        return True
    
    # æ›´æ–°moyun.json
    moyun_data['sites'] = valid_sites
    
    # æ·»åŠ åŒæ­¥ä¿¡æ¯åˆ°é…ç½®ä¸­
    if 'sync_info' not in moyun_data:
        moyun_data['sync_info'] = {}
    
    moyun_data['sync_info'].update({
        'last_sync': datetime.now().isoformat(),
        'source_file': os.path.basename(spider_file),
        'sites_count': len(valid_sites),
        'sync_script': 'sync_sites.py'
    })
    
    # ä¿å­˜æ–‡ä»¶
    success = save_json_file(moyun_data, moyun_file, backup=True)
    
    if success:
        print("ğŸ‰ Sitesé…ç½®åŒæ­¥å®Œæˆï¼")
        return True
    else:
        print("âŒ åŒæ­¥å¤±è´¥")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ”„ Spider Sites åŒæ­¥å·¥å…·")
    print("=" * 60)
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    dry_run = '--dry-run' in sys.argv or '--preview' in sys.argv
    
    # è·å–æ–‡ä»¶è·¯å¾„
    script_dir = Path(__file__).parent
    
    # ä¼˜å…ˆä½¿ç”¨GitHub Actionså·¥ä½œåŒºè·¯å¾„ï¼Œå¦åˆ™ä½¿ç”¨è„šæœ¬çˆ¶ç›®å½•
    if 'GITHUB_WORKSPACE' in os.environ:
        workspace = Path(os.environ['GITHUB_WORKSPACE'])
        spider_file = workspace / 'spider.json'
        moyun_file = workspace / 'moyun.json'
        working_dir = workspace
    else:
        # æœ¬åœ°è¿è¡Œæ—¶ï¼Œæ–‡ä»¶åœ¨è„šæœ¬çš„çˆ¶ç›®å½•ï¼ˆé¡¹ç›®æ ¹ç›®å½•ï¼‰
        working_dir = script_dir.parent
        spider_file = working_dir / 'spider.json'
        moyun_file = working_dir / 'moyun.json'
    
    print(f"ğŸ” å·¥ä½œç›®å½•: {working_dir}")
    print(f"ğŸ“ Spideræ–‡ä»¶: {spider_file}")
    print(f"ğŸ“ Moyunæ–‡ä»¶: {moyun_file}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not spider_file.exists():
        print(f"âŒ spider.json æ–‡ä»¶ä¸å­˜åœ¨: {spider_file}")
        sys.exit(1)
    
    if not moyun_file.exists():
        print(f"âŒ moyun.json æ–‡ä»¶ä¸å­˜åœ¨: {moyun_file}")
        sys.exit(1)
    
    # æ‰§è¡ŒåŒæ­¥
    try:
        success = sync_sites(str(spider_file), str(moyun_file), dry_run=dry_run)
        if success:
            print("\nâœ… åŒæ­¥æ“ä½œå®Œæˆ")
            sys.exit(0)
        else:
            print("\nâŒ åŒæ­¥æ“ä½œå¤±è´¥")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nğŸ’¥ å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()